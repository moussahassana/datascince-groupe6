{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/100, error=0.8638013354839185\n",
      "2/100, error=0.7891108005904128\n",
      "3/100, error=0.7317853815692537\n",
      "4/100, error=0.6664389063188166\n",
      "5/100, error=0.576806142952728\n",
      "6/100, error=0.4562971807542781\n",
      "7/100, error=0.32270389158268115\n",
      "8/100, error=0.2219257093713864\n",
      "9/100, error=0.17933398004809997\n",
      "10/100, error=0.15558950314599265\n",
      "11/100, error=0.13792174201113133\n",
      "12/100, error=0.12452729976127111\n",
      "13/100, error=0.11684951739581233\n",
      "14/100, error=0.11119095654853957\n",
      "15/100, error=0.10521897153673741\n",
      "16/100, error=0.10004776335819313\n",
      "17/100, error=0.09614648117070043\n",
      "18/100, error=0.09396690857192916\n",
      "19/100, error=0.09224659987729432\n",
      "20/100, error=0.09090516102168465\n",
      "21/100, error=0.0896097728185031\n",
      "22/100, error=0.08839353231072047\n",
      "23/100, error=0.08721808108541591\n",
      "24/100, error=0.08604226702130048\n",
      "25/100, error=0.08495052117503411\n",
      "26/100, error=0.083895692413635\n",
      "27/100, error=0.08289689671005473\n",
      "28/100, error=0.08204761591631617\n",
      "29/100, error=0.08121164546221078\n",
      "30/100, error=0.08035926345422115\n",
      "31/100, error=0.0796368417289474\n",
      "32/100, error=0.07888306247925526\n",
      "33/100, error=0.07807193965725658\n",
      "34/100, error=0.07735187659520718\n",
      "35/100, error=0.07660734506105982\n",
      "36/100, error=0.07589939553207724\n",
      "37/100, error=0.0753409384089982\n",
      "38/100, error=0.07464404991645457\n",
      "39/100, error=0.07400305338826532\n",
      "40/100, error=0.07348764187597731\n",
      "41/100, error=0.07297054308885602\n",
      "42/100, error=0.07245300946270251\n",
      "43/100, error=0.07200712966411867\n",
      "44/100, error=0.0715839710185305\n",
      "45/100, error=0.07117757522503788\n",
      "46/100, error=0.0707841371921758\n",
      "47/100, error=0.07038808540398067\n",
      "48/100, error=0.0699876110324365\n",
      "49/100, error=0.06959606601063184\n",
      "50/100, error=0.06922445063711671\n",
      "51/100, error=0.06886181246585713\n",
      "52/100, error=0.0685074710647495\n",
      "53/100, error=0.06814393369358251\n",
      "54/100, error=0.06775945348288218\n",
      "55/100, error=0.06734544039833752\n",
      "56/100, error=0.06686014105564907\n",
      "57/100, error=0.06652183445549512\n",
      "58/100, error=0.06623393298025143\n",
      "59/100, error=0.06595804060588742\n",
      "60/100, error=0.06566648009761081\n",
      "61/100, error=0.0653818064407155\n",
      "62/100, error=0.06509049047572092\n",
      "63/100, error=0.064813164167979\n",
      "64/100, error=0.06448914479248703\n",
      "65/100, error=0.06420598044313776\n",
      "66/100, error=0.0639466803336199\n",
      "67/100, error=0.06372245784776268\n",
      "68/100, error=0.06347092322832146\n",
      "69/100, error=0.06323480634668924\n",
      "70/100, error=0.06295969240480247\n",
      "71/100, error=0.06273234586483264\n",
      "72/100, error=0.0625068089611164\n",
      "73/100, error=0.06232515295247744\n",
      "74/100, error=0.062106488367428984\n",
      "75/100, error=0.061920714589573406\n",
      "76/100, error=0.06170396887054087\n",
      "77/100, error=0.06155444304751997\n",
      "78/100, error=0.061376353164240664\n",
      "79/100, error=0.06124698782920822\n",
      "80/100, error=0.06106283602358147\n",
      "81/100, error=0.06094041233074533\n",
      "82/100, error=0.06080689977854987\n",
      "83/100, error=0.06070165086524482\n",
      "84/100, error=0.06051309973403748\n",
      "85/100, error=0.06037410614702396\n",
      "86/100, error=0.0602504739194375\n",
      "87/100, error=0.06015396298030993\n",
      "88/100, error=0.05997328195575416\n",
      "89/100, error=0.059864503392918295\n",
      "90/100, error=0.05978034208641528\n",
      "91/100, error=0.05968992741142865\n",
      "92/100, error=0.05951335891161996\n",
      "93/100, error=0.059412949722356126\n",
      "94/100, error=0.05933282337355064\n",
      "95/100, error=0.059237166994639066\n",
      "96/100, error=0.0590593030963164\n",
      "97/100, error=0.05896492180869463\n",
      "98/100, error=0.05886751182407094\n",
      "99/100, error=0.05876742296797198\n",
      "100/100, error=0.05859103755684158\n",
      "pred: 7 \ttrue: 7\n",
      "pred: 6 \ttrue: 2\n",
      "pred: 1 \ttrue: 1\n",
      "pred: 0 \ttrue: 0\n",
      "pred: 9 \ttrue: 4\n",
      "pred: 1 \ttrue: 1\n",
      "pred: 4 \ttrue: 4\n",
      "pred: 7 \ttrue: 9\n",
      "pred: 4 \ttrue: 5\n",
      "pred: 4 \ttrue: 9\n",
      "pred: 2 \ttrue: 0\n",
      "pred: 4 \ttrue: 6\n",
      "pred: 9 \ttrue: 9\n",
      "pred: 0 \ttrue: 0\n",
      "pred: 1 \ttrue: 1\n",
      "pred: 6 \ttrue: 5\n",
      "pred: 9 \ttrue: 9\n",
      "pred: 7 \ttrue: 7\n",
      "pred: 6 \ttrue: 3\n",
      "pred: 4 \ttrue: 4\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'MNIST' from 'mnist' (c:\\Users\\Serval T. Nono\\Documents\\Mon Master 2\\Data Science\\TPE-CC\\datascince-groupe6\\2e TPE CNN\\Neural-Network-master\\mnist.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12312\\865800820.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmnist\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMNIST\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'MNIST' from 'mnist' (c:\\Users\\Serval T. Nono\\Documents\\Mon Master 2\\Data Science\\TPE-CC\\datascince-groupe6\\2e TPE CNN\\Neural-Network-master\\mnist.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Définition des fonctions d'activation et de perte\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def softmax(x):\n",
    "    exps = np.exp(x - np.max(x))\n",
    "    return exps / np.sum(exps, axis=1, keepdims=True)\n",
    "\n",
    "def categorical_crossentropy(y_true, y_pred):\n",
    "    return -np.mean(np.sum(y_true * np.log(y_pred), axis=1))\n",
    "\n",
    "# Définition du réseau CNN\n",
    "class CNN:\n",
    "    def __init__(self):\n",
    "        self.conv_weights = np.random.randn(3, 3, 1, 8)\n",
    "        self.conv_bias = np.zeros((1, 8))\n",
    "        self.fc_weights = np.random.randn(13*13*8, 10)\n",
    "        self.fc_bias = np.zeros((1, 10))\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Convolution\n",
    "        self.conv_output = np.zeros((X.shape[0], 26, 26, 8))\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(26):\n",
    "                for k in range(26):\n",
    "                    self.conv_output[i, j, k] = sigmoid(np.sum(X[i, j:j+3, k:k+3] * self.conv_weights) + self.conv_bias)\n",
    "\n",
    "        # Flatten\n",
    "        self.flatten_output = self.conv_output.reshape(X.shape[0], -1)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc_output = softmax(np.dot(self.flatten_output, self.fc_weights) + self.fc_bias)\n",
    "        return self.fc_output\n",
    "\n",
    "    def backward(self, X, y, lr=0.01):\n",
    "        # Compute gradients for fully connected layer\n",
    "        fc_grad = (self.fc_output - y) / y.shape[0]\n",
    "        self.fc_weights_grad = np.dot(self.flatten_output.T, fc_grad)\n",
    "        self.fc_bias_grad = np.sum(fc_grad, axis=0, keepdims=True)\n",
    "\n",
    "        # Compute gradients for convolutional layer\n",
    "        conv_grad = np.dot(fc_grad, self.fc_weights.T) * sigmoid_derivative(self.flatten_output)\n",
    "        conv_grad = conv_grad.reshape(X.shape[0], 26, 26, 8)\n",
    "\n",
    "        self.conv_weights_grad = np.zeros_like(self.conv_weights)\n",
    "        self.conv_bias_grad = np.zeros_like(self.conv_bias)\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(26):\n",
    "                for k in range(26):\n",
    "                    self.conv_weights_grad += X[i, j:j+3, k:k+3] * conv_grad[i, j, k][:, np.newaxis]\n",
    "                    self.conv_bias_grad += conv_grad[i, j, k]\n",
    "\n",
    "        # Update weights and biases\n",
    "        self.fc_weights -= lr * self.fc_weights_grad\n",
    "        self.fc_bias -= lr * self.fc_bias_grad\n",
    "        self.conv_weights -= lr * self.conv_weights_grad\n",
    "        self.conv_bias -= lr * self.conv_bias_grad\n",
    "\n",
    "# Chargement des données MNIST\n",
    "mndata = mnist('./data')\n",
    "images, labels = mndata.load_training()\n",
    "\n",
    "# Prétraitement des données\n",
    "X = np.array(images).reshape(-1, 28, 28) / 255.0\n",
    "y = np.zeros((len(labels), 10))\n",
    "y[np.arange(len(labels)), labels] = 1\n",
    "\n",
    "# Création des ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entraînement du modèle\n",
    "cnn = CNN()\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        batch_X, batch_y = X_train[i:i+batch_size], y_train[i:i+batch_size]\n",
    "        cnn.forward(batch_X)\n",
    "        cnn.backward(batch_X, batch_y)\n",
    "\n",
    "# Inférence sur le dataset de test\n",
    "y_pred = np.argmax(cnn.forward(X_test), axis=1)\n",
    "\n",
    "# Calcul de l'accuracy\n",
    "accuracy = accuracy_score(np.argmax(y_test, axis=1), y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Affichage de la matrice de confusion\n",
    "conf_matrix = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Affichage de l'évolution de l'accuracy pendant l'entraînement\n",
    "plt.plot(range(1, epochs + 1), accuracies)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
